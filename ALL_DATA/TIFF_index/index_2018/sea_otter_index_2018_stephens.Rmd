---
title: "SO_Index_2018_Stephens"
author: "Tiff Stephens; adapted from Wendel Raymonds 2017 index code"
date: "10/18/2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages
Since we will be working with spatial data we need to load a bunch of packages that deal with spatial data.
```{r libraries}
library(dplyr)
library(tidyr)
library(ggplot2)
library(rgdal)
library(rgeos)
library(raster)
library(gdistance)
library(spatstat)
library(leaflet)
library(DT)
library(sf)
library(compare)
library(corrgram)
library(sp)

theme_set(theme_classic())
```

\Sites
```{r data}
# import sites as .csv file
df.sites <- read.csv("/Users/tiff/Desktop/R Studio/APECS-master-repos/ALL_DATA/TIFF_index/index_2018/sites_2018_stephens.csv", stringsAsFactors = FALSE, header = TRUE)
str(df.sites)
```

\OtterCount
```{r}
# import otter counts as .csv file
df.otts <- read.csv("/Users/tiff/Desktop/R Studio/APECS-master-repos/ALL_DATA/TIFF_index/index_2018/sea_otter_counts_2018_stephens_all.csv", stringsAsFactors = FALSE, header = TRUE)


df.otts <- df.otts[,-c(8, 9)] # remove empty columns


# calculate total otters per site (within 2 nm buffer)
df.otts.sums <- aggregate(n_otter ~ site + replicate, data = df.otts, sum, na.rm = TRUE)
head(df.otts.sums)


library(reshape)
df.otts.sums <- spread(df.otts.sums, key = replicate, value = n_otter) # split count surveys into two columns
colnames(df.otts.sums)[2] <- "n_otter1" # change column names
colnames(df.otts.sums)[3] <- "n_otter2" # change column names
```


## Calculating survey density
The general steps are as follows
1. Calculate survey area centered at each survey site and bounded by 2 nm "as the otter swims". It is essential that site points intersect the water polygon!
2. Calculate area of above survey area
3. Calculate density by counting number of otters in each area (and each survey instance if necessary) and dividing by the survey area
```{r loop to extract surveyed otters to sites}
# Combine sites and otter count dfs
df.otts <- left_join(df.sites, df.otts.sums, by = c("site"))

rm(df.otts.sums) # remove uneccesary df

# Calculate otter mean count and densities for 2 nm buffer around each site
df.otts = df.otts %>% 
  mutate(so_n_avg = (n_otter1 + n_otter2) / 2) %>%
  mutate(so_dens_km2_1 = (n_otter1 / site_polygon_area_km2)) %>%
  mutate(so_dens_km2_2 = (n_otter2 / site_polygon_area_km2)) %>%
  mutate (so_dens_avg = (so_dens_km2_1 + so_dens_km2_2) / 2)



df.otts <- df.otts[,-c(5:7)] # remove unneccessary columns

colnames(df.otts)[4] <- "so_region" # change column names
colnames(df.otts)[5] <- "site_water_area_km2" # change column names
colnames(df.otts)[8] <- "so_tinker_km2_1" # change column names
colnames(df.otts)[9] <- "so_tinker_km2_2" # change column names
colnames(df.otts)[10] <- "so_n_1" # change column names
colnames(df.otts)[11] <- "so_n_2" # change column names
```

Lets view the final table.
```{r}
DT::datatable(df.otts, caption = "Sea otter survey data")
```






```{r}
# import pits and sediment quality data as .csv file
df.pits <- read.csv("/Users/tiff/Desktop/R Studio/APECS-master-repos/ALL_DATA/TIFF_index/index_2018/pits_trimmed.csv", stringsAsFactors = FALSE, header = TRUE)
str(df.pits)

# calculate total pits per site
df.pits.stack <- aggregate(n_pits ~ site + trans_loc, data = df.pits, sum, na.rm = TRUE)
#df.pits.tot <- aggregate(n_pits ~ site, data = df.pits, sum, na.rm = TRUE)

library(reshape)
df.pits.trans <- spread(df.pits.stack, key = trans_loc, value = n_pits) # split count surveys into three columns
colnames(df.pits.trans)[2] <- "pits_edge" # change column names
colnames(df.pits.trans)[3] <- "pits_inside" # change column names
colnames(df.pits.trans)[4] <- "pits_outside" # change column names

df.pits.trans = df.pits.trans %>% 
  mutate(pits_all_outside = pits_edge + pits_outside) %>%
  mutate(pits_all = pits_edge + pits_outside + pits_inside)

df.pits.trans <- df.pits.trans[ -c(2, 3, 4) ] # remove unneccessary columns
```

```{r}
### For the SO Index, we will use the site totals; join here
df.index <- left_join(df.otts, df.pits.trans, by = c("site"))


rm(df.pits)
rm(df.pits.trans)
rm(df.pits.stack)
rm(df.sites)
rm(df.otts)
```



# 5. Proportion of sea otter crakced clam shells
Finally we want to account for the proportion are clam shells that appear to have been cracked (consumed) by sea otters.

## Data
You will need
1. Sea otter clam data
```{r}
# import pits and sediment quality data as .csv file
df.shells <- read.csv("/Users/tiff/Desktop/R Studio/APECS-master-repos/ALL_DATA/TIFF_index/index_2018/clamshells_trimmed.csv", stringsAsFactors = FALSE, header = TRUE)
str(df.shells)
```

The data will need to be summed by site and then converted to a proportion and appended to the rest of the data
```{r}
# calculate shell count per death per site
df.shells <- df.shells %>%
    group_by(site, death_estimate) %>% 
    summarise(n_shells = n())

# split column so that each death is its own column
df.shells.split <- spread(df.shells, key = death_estimate, value = n_shells) # split counts into three columns



df.shells.split[is.na(df.shells.split)] <- 0 # convert all NA into 0
colnames(df.shells.split)[2] <- "death_crab" # change column names
colnames(df.shells.split)[3] <- "death_drill" # change column names
colnames(df.shells.split)[4] <- "death_otter" # change column names
colnames(df.shells.split)[5] <- "death_whole" # change column names


# Proportion of shells that where sea otter cracked by site
df.shells <- df.shells.split %>%
  mutate(prop_otter_shells = death_otter / (death_crab + death_drill + death_otter + death_whole))

df.shells <- df.shells[ -c(2, 3, 5) ] # remove columns that are no longer necessary
colnames(df.shells)[2] <- "shells_n_otter" # change column names
colnames(df.shells)[3] <- "shells_prop_otter" # change column names

# join proportion otter shells to index df
df.index <- left_join(df.index, df.shells, by = c("site"))

rm(df.shells)
rm(df.shells.split)
```









# Calculating the actual index
Congratulaitons! You calculated and complied all the data you need to actually calculate the index
```{r}
linear.model <- (y ~ x)
poly.model <- y ~ poly(x,2)


pz4 = ggplot(df.index, aes(site_water_area_km2, so_dens_avg)) +
  geom_point(size=3) + # allows for trendline on general trend
  #geom_smooth(method=lm, formula=y ~ poly(x,2), se=FALSE, fullrange=FALSE) +
  geom_smooth(method=lm, formula=y~x, se=FALSE, fullrange=FALSE) +
  #geom_smooth(method=lm, formula=(log(y+60) ~ x), se=FALSE, fullrange=FALSE) +
  #geom_smooth(method=lm, formula = -(log(y) ~ x), se=FALSE, fullrange=FALSE) +
  #xlab("Sea Otter Index")+ylab("Diffuse edge elevation (cm, MLLW)") +
  #theme(legend.title=element_text(size=8), legend.text=element_text(size=8)) +
  #geom_text(aes(label=site), size=2)
  stat_poly_eq(formula = linear.model, 
               aes(label = paste(..rr.label.., sep = "~~~")), 
               label.x.npc = 'right', label.y.npc = 'top', size = 5, parse = TRUE) +
  stat_fit_glance(method = 'lm', method.args = list(formula = linear.model), geom = 'text',
                  aes(label = paste("P-value = ", signif(..p.value.., digits = 3), sep = "")),
                  label.x.npc = 'left', label.y.npc = 'top', size = 5)
plot(pz4)
```



\soi
\1
## Sea otter impact index
We will be using a principle components analysis to create the sea otter impact index. First its good practice to examine the data a bit. Correlation plots indicate that most measures are reasonably correlated with eachother.
```{r data exploration}
# Correlations

corrgram(df.index[, c(6,8,15,17,19)]) # so_duration_1, so_tinker_km2_1, so_dens_avg, pits_all, shells_prop_otter
pairs(df.index[, c(6,8,15,17,19)])
```

Checking for normality is important. Histograms suggest that theses data should be log transformed. 
```{r}
# histograms
hist(df.index$so_dens_avg)
hist(df.index$pits_all)
hist(df.index$shells_prop_otter)

# log transformation
hist(log(df.index$so_dens_avg + 1))
hist(log(df.index$pits_all + 1))
hist(log(df.index$shells_prop_otter + 1))
```
Histograms indicate that the data are right skewed. Log transformation helps this somewhat.

Given the distributions of the data we will log transform the heavily skewed data to meet (or better attempt to) assumptions of normality.
```{r transformations}
# Separate values only
dat.redu <- df.index[,c(6,8,15,17,19)]

# log transform appropriate columns
dat.l <- cbind(dat.redu[,1:2], log(dat.redu[,c(3:5)] + 1)) 
pairs(dat.l)

# Standardize to column (sea otter measure) maximum
dat.std.l <- scale(dat.l, center = FALSE, scale = apply(dat.l, 2, max))
```

Now we can calculate the PCA
```{r PCA}
# PCA on transformed AND standarized data
pca <- princomp(dat.std.l)
pca.summary <- summary(pca)
loadings(pca)
biplot(pca, cex = 1) # display
screeplot(pca, ylim = c(0, 0.8))
pca$scores 
df.pcascores <-pca$scores 

final.dat <- cbind(df.index, pca$scores[,1:2])
colnames(final.dat)[20] <- "so_index_pc1"
colnames(final.dat)[21] <- "so_index_pc2"


# Switch sign of index so positive values are associated with more otters
final.dat$so_index_pc1 <- final.dat$so_index_pc1 * -1
final.dat$so_index_pc2 <- final.dat$so_index_pc2 * -1


# plots for pc1
ggplot(final.dat, aes(site, so_index_pc1)) +
  geom_point(size = 4) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "site", y = "sea otter index (PC1)")

ggplot(final.dat, aes(reorder(site, so_index_pc1), so_index_pc1, col = so_index_pc1)) +
  geom_point(size = 4) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(x = "site", y = "SO index PC1", col = "SO index (mean density)") +
  theme(text = element_text(size = 12), axis.ticks = element_line(size = 2)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0))

# plots for pc2
ggplot(final.dat, aes(site, so_index_pc2)) +
  geom_point(size = 4) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "site", y = "sea otter index (PC1)")

ggplot(final.dat, aes(reorder(site, so_index_pc2), so_index_pc2, col = so_index_pc2)) +
  geom_point(size = 4) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(x = "site", y = "SO index PC2", col = "SO index (mean density)") +
  theme(text = element_text(size = 12), axis.ticks = element_line(size = 2)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0))
```

Final index data table
```{r}
DT::datatable(final.dat, caption = "sea otter impact index")
```

## Data export
```{r export}
# Data Export
write.csv(final.dat, "/Users/tiff/Desktop/R Studio/APECS-master-repos/ALL_DATA/TIFF_index/index_2018/soi_1.csv", row.names = FALSE)
```





















\soi
\2
## Sea otter impact index
We will be using a principle components analysis to create the sea otter impact index. First its good practice to examine the data a bit. Correlation plots indicate that most measures are reasonably correlated with eachother.
```{r data exploration}
# Correlations

corrgram(df.index[, c(6,8,15,17,18,19)]) # so_duration_1, so_tinker_km2_1, so_dens_avg, pits_all, shells_n_otter shells_prop_otter
pairs(df.index[, c(6,8,15,17,18,19)])
```

Checking for normality is important. Histograms suggest that theses data should be log transformed. 
```{r}
# histograms
hist(df.index$so_dens_avg)
hist(df.index$pits_all)
hist(df.index$shells_n_otter)
hist(df.index$shells_prop_otter)

# log transformation
hist(log(df.index$so_dens_avg + 1))
hist(log(df.index$pits_all + 1))
hist(log(df.index$shells_n_otter + 1))
hist(log(df.index$shells_prop_otter + 1))
```
Histograms indicate that the data are right skewed. Log transformation helps this somewhat.

Given the distributions of the data we will log transform the heavily skewed data to meet (or better attempt to) assumptions of normality.
```{r transformations}
# Separate values only
dat.redu <- df.index[,c(6,8,15,17,18,19)]

# log transform appropriate columns
dat.l <- cbind(dat.redu[,1:2], log(dat.redu[,c(3:6)] + 1)) 
pairs(dat.l)

# Standardize to column (sea otter measure) maximum
dat.std.l <- scale(dat.l, center = FALSE, scale = apply(dat.l, 2, max))
```

Now we can calculate the PCA
```{r PCA}
# PCA on transformed AND standarized data
pca <- princomp(dat.std.l)
summary(pca, standardized = TRUE, fit.measures = TRUE)
loadings(pca)
biplot(pca, cex = 1) # display
screeplot(pca, ylim = c(0, 0.8))
pca$scores 
df.pcascores <-pca$scores 

final.dat <- cbind(df.index, pca$scores[,1:2])
colnames(final.dat)[20] <- "so_index_pc1"
colnames(final.dat)[21] <- "so_index_pc2"


# Switch sign of index so positive values are associated with more otters
final.dat$so_index_pc1 <- final.dat$so_index_pc1 * -1
final.dat$so_index_pc2 <- final.dat$so_index_pc2 * -1


# plots for pc1
ggplot(final.dat, aes(site, so_index_pc1)) +
  geom_point(size = 4) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "site", y = "sea otter index (PC1)")

ggplot(final.dat, aes(reorder(site, so_index_pc1), so_index_pc1, col = so_index_pc1)) +
  geom_point(size = 4) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(x = "site", y = "SO index PC1", col = "SO index (mean density)") +
  theme(text = element_text(size = 12), axis.ticks = element_line(size = 2)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0))

# plots for pc2
ggplot(final.dat, aes(site, so_index_pc2)) +
  geom_point(size = 4) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "site", y = "sea otter index (PC1)")

ggplot(final.dat, aes(reorder(site, so_index_pc2), so_index_pc2, col = so_index_pc2)) +
  geom_point(size = 4) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(x = "site", y = "SO index PC2", col = "SO index (mean density)") +
  theme(text = element_text(size = 12), axis.ticks = element_line(size = 2)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0))
```

Final index data table
```{r}
DT::datatable(final.dat, caption = "sea otter impact index")
```

## Data export
```{r export}
# Data Export
write.csv(final.dat, "/Users/tiff/Desktop/R Studio/APECS-master-repos/ALL_DATA/TIFF_index/index_2018/soi_2.csv", row.names = FALSE)
```



















\soi
\3
## Sea otter impact index
We will be using a principle components analysis to create the sea otter impact index. First its good practice to examine the data a bit. Correlation plots indicate that most measures are reasonably correlated with eachother.
```{r data exploration}
# Correlations

corrgram(df.index[, c(6,8,15,17,18)]) # so_duration_1, so_tinker_km2_1, so_dens_avg, pits_all, shells_n_otter shells_prop_otter
pairs(df.index[, c(6,8,15,17,18)])
```

Checking for normality is important. Histograms suggest that theses data should be log transformed. 
```{r}
# histograms
hist(df.index$so_dens_avg)
hist(df.index$pits_all)
hist(df.index$shells_n_otter)

# log transformation
hist(log(df.index$so_dens_avg + 1))
hist(log(df.index$pits_all + 1))
hist(log(df.index$shells_n_otter + 1))
```
Histograms indicate that the data are right skewed. Log transformation helps this somewhat.

Given the distributions of the data we will log transform the heavily skewed data to meet (or better attempt to) assumptions of normality.
```{r transformations}
# Separate values only
dat.redu <- df.index[,c(6,8,15,17,18)]

# log transform appropriate columns
dat.l <- cbind(dat.redu[,1:2], log(dat.redu[,c(3:5)] + 1)) 
pairs(dat.l)

# Standardize to column (sea otter measure) maximum
dat.std.l <- scale(dat.l, center = FALSE, scale = apply(dat.l, 2, max))
```

Now we can calculate the PCA
```{r PCA}
# PCA on transformed AND standarized data
pca <- princomp(dat.std.l)
summary(pca, standardized = TRUE, fit.measures = TRUE)
loadings(pca)
biplot(pca, cex = 1) # display
screeplot(pca, ylim = c(0, 0.8))
pca$scores 
df.pcascores <-pca$scores 

final.dat <- cbind(df.index, pca$scores[,1:2])
colnames(final.dat)[20] <- "so_index_pc1"
colnames(final.dat)[21] <- "so_index_pc2"


# Switch sign of index so positive values are associated with more otters
final.dat$so_index_pc1 <- final.dat$so_index_pc1 * -1
final.dat$so_index_pc2 <- final.dat$so_index_pc2 * -1


# plots for pc1
ggplot(final.dat, aes(site, so_index_pc1)) +
  geom_point(size = 4) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "site", y = "sea otter index (PC1)")

ggplot(final.dat, aes(reorder(site, so_index_pc1), so_index_pc1, col = so_index_pc1)) +
  geom_point(size = 4) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(x = "site", y = "SO index PC1", col = "SO index (mean density)") +
  theme(text = element_text(size = 12), axis.ticks = element_line(size = 2)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0))

# plots for pc2
ggplot(final.dat, aes(site, so_index_pc2)) +
  geom_point(size = 4) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "site", y = "sea otter index (PC1)")

ggplot(final.dat, aes(reorder(site, so_index_pc2), so_index_pc2, col = so_index_pc2)) +
  geom_point(size = 4) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(x = "site", y = "SO index PC2", col = "SO index (mean density)") +
  theme(text = element_text(size = 12), axis.ticks = element_line(size = 2)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0))
```

Final index data table
```{r}
DT::datatable(final.dat, caption = "sea otter impact index")
```

## Data export
```{r export}
# Data Export
write.csv(final.dat, "/Users/tiff/Desktop/R Studio/APECS-master-repos/ALL_DATA/TIFF_index/index_2018/soi_3.csv", row.names = FALSE)
```











\\\\\\\\\\\\
```{r}
df.soi1 <- read.csv("/Users/tiff/Desktop/R Studio/APECS-master-repos/ALL_DATA/TIFF_index/index_2018/soi_1.csv", stringsAsFactors = FALSE, header = TRUE)

df.soi2 <- read.csv("/Users/tiff/Desktop/R Studio/APECS-master-repos/ALL_DATA/TIFF_index/index_2018/soi_2.csv", stringsAsFactors = FALSE, header = TRUE)

df.soi3 <- read.csv("/Users/tiff/Desktop/R Studio/APECS-master-repos/ALL_DATA/TIFF_index/index_2018/soi_3.csv", stringsAsFactors = FALSE, header = TRUE)



colnames(df.soi1)[20] <- "soi1_pc1"
colnames(df.soi1)[21] <- "soi1_pc2"

df.soi2 <- df.soi2[ -c(2:19) ] # remove columns that are no longer necessary
colnames(df.soi2)[2] <- "soi2_pc1"
colnames(df.soi2)[3] <- "soi2_pc2"

df.soi3 <- df.soi3[ -c(2:19) ] # remove columns that are no longer necessary
colnames(df.soi3)[2] <- "soi3_pc1"
colnames(df.soi3)[3] <- "soi3_pc2"




# join proportion otter shells to index df
df.index <- left_join(df.soi1, df.soi2, by = c("site"))
df.index <- left_join(df.index, df.soi3, by = c("site"))
```

## Data export
```{r export}
# Data Export
write.csv(df.index, "/Users/tiff/Desktop/R Studio/APECS-master-repos/ALL_DATA/TIFF_index/index_2018/so_index_stephens.csv", row.names = FALSE)
```


