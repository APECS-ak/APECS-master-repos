---
title: "SO_Index_2018_Stephens"
author: "Tiff Stephens; adapted from Wendel Raymonds 2017 index code"
date: "10/18/2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Sea otter index
Sea otters are hard to keep track of. Until the 2017 and 2018 field seasons, the most reliable measure of sea otters in the Prince of Wales Island region were the USFWS aerial surveys. These data provided densities and time since occupation of sea otters. However the most recent survey was done in 2011. In an effort to add more resolution to how we think about sea otters we collected a variety of sea otter impact measures over the 2017 field season. This script summaries and then combined these measures to create a sea otter impact index. 

## Note for non-eelgrass site users
This script provides the details of how to calculate the sea otter index for eelgrass sites. You may want to do this differently. You my also have to clean up the resulting data in a different way than it is done here, because of how your data is formated etc. This script should be "generalizable" though and it should not be terribly difficult to create a new version of this code that suits a slightly different set of needs.

# Getting started
In this script we will calculate the sea otter impact index from raw data to final index. This will be in contrast to relying on hard to track ArcGIS processing. The original index uses the following data that will be attributed to each site:

1. Sea otter density from 2018 boat based sea otter surveys (otters/km2)
2. The duration of sea otter occupation based in USFWS aerial surveys (years)
3. Sea otter density derived from Tinker et al. population model estimates (otters/km2)
4. Number of sea otter pits counted at a site (count)
5. Proportion of sea otter cracked shells (proportion)

Below, raw data is processed such that the final output is a table of sites with the corresponding values for each of these categories. Then that data can be fed into the principle components analysis that generaates the actual index.


## Packages
Since we will be working with spatial data we need to load a bunch of packages that deal with spatial data.
```{r libraries}
library(dplyr)
library(tidyr)
library(ggplot2)
library(rgdal)
library(rgeos)
library(raster)
library(gdistance)
library(spatstat)
library(leaflet)
library(DT)
library(sf)
library(compare)
library(corrgram)
library(sp)

theme_set(theme_classic())
```




# 1. Sea otter density from boat based surveys
Two replicate surveys were conducted, a density will be calculated for each survey.

## Data
You will need data on.
1. Sites from which sea otter surveys were centered from (points)
2. Sea otter survey data (points with an "n sea otter" data attribute)
3. A polygon of the water around the study area. In this case I am using a polygon of all the coastal waters of POW.

\SITES
```{r data}

# import sites as .csv file
df.sites <- read.csv("/Users/tiff/Desktop/R Studio/APECS-master-repos/sea_otter_index_2018/sites_2018_stephens.csv", stringsAsFactors = FALSE, header = TRUE)
str(df.sites)

# convert .csv file into spatial file
utm8CRS <- crs("+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0") # assign crs to object

sp.sites <- SpatialPointsDataFrame(df.sites[,2:3],
                    df.sites,    #the R object to convert
                    proj4string = utm8CRS)   # assign a CRS 

# plot spatial object to check general accuracy of site locations
plot(sp.sites, 
     main="Map of Plot Sites")

# write spatial frame into shapefile
writeOGR(sp.sites, "/Users/tiff/Desktop/R Studio/APECS-master-repos/sea_otter_index_2018/spatial_data",
         "sp_sites", driver="ESRI Shapefile")

# READ SPATIAL FILE FOR SITES
sp.sites <- readOGR(dsn = "/Users/tiff/Desktop/R Studio/APECS-master-repos/sea_otter_index_2018/spatial_data", layer = "sp_sites")
sites.eg <- subset(sp.sites)
```

\OTTERS
```{r}
# import otter counts as .csv file
df.otts <- read.csv("/Users/tiff/Desktop/R Studio/APECS-master-repos/sea_otter_index_2018/sea_otter_counts_2018_stephens.csv", stringsAsFactors = FALSE, header = TRUE)
df.otts$so_count <- as.numeric(df.otts$so_count)

# convert .csv file into spatial file
utm8CRS <- crs("+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0") # assign crs to object

sp.otts <- SpatialPointsDataFrame(df.otts[,2:3],
                    df.otts,    #the R object to convert
                    proj4string = utm8CRS)   # assign a CRS 

# plot spatial object to check general accuracy of site locations
plot(sp.otts, 
     main="Map of Sea Otter Count Waypoints")

# write spatial frame into shapefile
writeOGR(sp.sites, "/Users/tiff/Desktop/R Studio/APECS-master-repos/sea_otter_index_2018/spatial_data",
         "sp_otts", driver="ESRI Shapefile")

# READ SPATIAL FILE FOR SITES
sp.otts <- readOGR(dsn = "/Users/tiff/Desktop/R Studio/APECS-master-repos/sea_otter_index_2018/spatial_data", layer = "sp_otts")
```

\H20
```{r}
## Prince of Wales Water Polygon
h2o.utm <- readOGR(dsn = "/Users/tiff/Desktop/R Studio/APECS-master-repos/sea_otter_index_2018/spatial_data", layer = "POW_water_UTM")
h2o.latlong <- spTransform(h2o.utm, CRS("+init=epsg:4326"))
```




## Plot sites and sea otters
Lets see what this all looks like. Note that when plotting with leaflet it helps to have the data in a lat/long progection.  
```{r plotting everything}
leaflet() %>% 
  addTiles() %>% 
  addPolygons(data = h2o.latlong, stroke = NA, fillColor = "blue", fillOpacity = 0.8, group = "POW") %>% 
  addMarkers(data = df.sites, ~longitude, ~latitude, label = ~site) %>% 
  addCircleMarkers(data = df.otts, ~longitude, ~latitude, color = "red", stroke = FALSE, radius = 5, fillOpacity = ~(so_count/max(so_count)))
```



## Calculating survey density
The general steps are as follows
1. Calculate survey area centered at each survey site and bounded by 2 nm "as the otter swims". It is essential that site points intersect the water polygon!
2. Calculate area of above survey area
3. Calculate density by counting number of otters in each area (and each survey instance if necessary) and dividing by the survey area

The following for loop generates a 2nm (== 3704 meter) as the otter swims survey area for each sites. It then selects the otters that were where sited in that survey area and generates a data table of that data. This is done for each site iterativley and the resulting data frames are pasted together. 
```{r loop to extract surveyed otters to sites}
d <- data.frame() # set up blank data frame to append to later
for(i in unique(1:26)){
  s <- sp.sites[i,] # subset sites 
  b <- gBuffer(s, byid = TRUE, width = 3704, quadsegs = 10) # create 3704 meter radius buffer around site
  b <- spTransform(b, CRS("+init=epsg:4326")) # change projection to for next step
  bw <- gIntersection(h2o.latlong, b, byid = TRUE) # clip the buffer area by water so we only have water area left
  bw <- spTransform(bw, CRS("+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0")) # change projection back to UTM
  e <- extent(bw) # save the extent of the polygon for later use
  r <- raster(xmn = e@xmin, xmx = e@xmax, ymn = e@ymin, ymx = e@ymax, ncol = (e@xmax - e@xmin) / 50, nrow = (e@ymax - e@ymin) / 50, crs = "+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0") # create a raster with 50 X 50 meter grid cells. This raster is "empty"
  wr <- rasterize(bw, r, crs = "+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0") # append water polygon data to raster. This raster is "full"
  wr[wr] <- 50 # convert all raster cell values to a value of 50 (because 50 meters)
  wt <- transition(wr, transitionFunction = function(x){50}, directions = 8) # conver raster to transition layer (required for accCost() below)
  wt <- geoCorrection(wt, type = "r", scl = FALSE) # not really sure what this actually does but you have to do it
  sa <- accCost(wt, s) # calculate the cumulative cost distance
  values(sa) <- (values(sa) * 50) # multiply cost values by 50 to reflect cost in terms of actual distance
  sa[values(sa) > 3700] <- NA # Convert cost rasters > 3700 to NA, now the raster will reflect the true survey area
  p <- rasterToPolygons(sa, dissolve = TRUE) # covert raster to polygon
  p <- spTransform(p, CRS("+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs")) # define projection
  a <- (2500 * length(p) / 1000000) # caculate area of the polygon in sq km. 2500 becasue 50*50=2500
  o <- over(p, sp.otts) # identifies surveyed otters that intersect/overlap with the polygon
  o <- as.data.frame(unique(o)) # convert that subset of otters to a data frame
  o$area <- a # append the area of the polygon to that data frame
  d <- rbind(d, o) # bind this data frame to the master one. -----> now go back to the top and start again!
}
```




Now we need to clean up the data frame generated in the for loop so that it is usable. *This will differ for everyone*.
```{r clean up data from above}
# Rename L05 to 2017_L_05
# levels(d$site)[levels(d$site) == "L05"] <- "2017_L_05"

# Count total otters are at each site survey date
ott.dat <- d %>% 
  group_by(site, date_MM.DD.YY) %>% 
  summarise(n = sum(so_count))

# Clean up NA row and funky site names
ott.dat <- ott.dat[c(1:8, 10:20, 22:30),]

# Fill in data. These are instances where multiple sites were surveyed at the same time.
fill <- data.frame(c("2017_H_04", "2017_H_06", "2017_M_02", "2017_M_03"), c("2017/07/21", "2017/07/21", "2017/08/05", "2017/08/05"), c(81,81,14,14))
colnames(fill) <- c("site", "survey_dat", "n")

# Compine fill in data with original and re summarise
ott.dat <- rbind.data.frame(ott.dat, fill)
ott.dat2 <- ott.dat %>% 
  group_by(site, survey_dat) %>% 
  summarise(n_otters = sum(n))

# Define survey 1 and 2
ott.dat2$survey <- as.factor(c(1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,2,1,2,1))
ott.dat.wide <- spread(ott.dat2[,c(1,3,4)], key = survey, value = n_otters)

# Merge with site data
site.dat <- sites.eg@data[,c(1,2,6:9)]
site.dat$area <- unique(d$area)
site.dat <- merge(site.dat, ott.dat.wide, by = "site", all.x = TRUE)
colnames(site.dat)[8] <- "n_surv1"
colnames(site.dat)[9] <- "n_surv2"

# NAs to 0
site.dat[is.na(site.dat)] <- 0

# Calculate density
site.dat$dens_surv1 <- site.dat$n_surv1 / site.dat$area
site.dat$dens_surv2 <- site.dat$n_surv2 / site.dat$area
```


