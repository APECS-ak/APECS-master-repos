---
title: 'Sea otter index - 2017 eelgrass edition'
author: "Wendel Raymond"
date: "December 14, 2017"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Sea otter index
Sea otters are hard to keep track of. Until the 2017 field season the most reliable measure of sea otters in the Prince of Wales Island region were the USFWS aerial surveys. These data provided densities and time since occupation of sea otters. However the most recent survey was done in 2011. In an effort to add more resolution to how we think about sea otters we collected a variety of sea otter impact measures over the 2017 field season. This script summaries and then combined these measures to create a sea otter impact index. 

## Note for non-eelgrass site users
This script provides the details of how to calculate the sea otter index for eelgrass sites. You may want to do this differently. You my also have to clean up the resulting data in a different way than it is done here, because of how your data is formated etc. This script should be "generalizable" though and it should not be terribly difficult to creat a new version of this code that suits a slightly differnt set of needs.

# Getting started
In this script we will calculate the sea otter impact index from raw data to final index. This will be in contrast to relying on hard to track ArcGIS processing. The original index uses the following data that will be attributed to each site.

1. Sea otter density from 2017 boat based sea otter surveys (otters/km2)
2. The duration of sea otter occupation based in USFWS aerial surveys (years)
3. Sea otter density derived from Tinker et al. population model estimates (otters/km2)
4. Number of sea otter pits counted at a site (count)
5. Proportion of sea otter cracked shells (proportion)

Below, raw data is processed such that the final output is a table of sites with the corresponding values for each of these categories. Then that data can be fed into the principle components analysis that generaates the actual index.

## Packages
Since we will be working with spatial data we need to load a bunch of packages that deal with spatial data.
```{r libraries}
library(dplyr)
library(tidyr)
library(ggplot2)
library(rgdal)
library(rgeos)
library(raster)
library(gdistance)
library(spatstat)
library(leaflet)
library(DT)
library(sf)
library(compare)
library(corrgram)
library(cowplot)

theme_set(theme_classic())
```

# 1. Sea otter density from boat based surveys
Two replicate surveys were conducted, a density will be calculated for each survey.

## Data
You will need data on.
1. Sites from which sea otter surveys were centered from (points)
2. Sea otter survey data (points with an "n sea otter" data attribute)
3. A polygon of the water around the study area. In this case I am using a polygon of all the coastal waters of POW.
```{r data}
## Sites ##
sites <- readOGR(dsn = "../ALL_DATA/spatial_data", layer = "Otter_Survey_Sites_2017_All_UTM")
sites.eg <- subset(sites, site_type %in% "Eelgrass")

## Sea otters that where observed ##
otts <- readOGR(dsn = "../ALL_DATA/spatial_data", layer = "Otter_Survey_All_10Jan18_UTM")
otts@data$n_otters <- as.numeric(as.character(otts@data$n_otters)) # data is imported as a factor

## Prince of Wales Water Polygon
h2o.utm <- readOGR(dsn = "../ALL_DATA/spatial_data", layer = "POW_water_UTM")
h2o.latlong <- spTransform(h2o.utm, CRS("+init=epsg:4326"))
```

## Plot sites and sea otters
Lets see what this all looks like. Note that when plotting with leaflet it helps to have the data in a lat/long progection.  
```{r plotting everything}
leaflet() %>% 
  addTiles() %>% 
  addPolygons(data = h2o.latlong, stroke = NA, fillColor = "blue", fillOpacity = 0.8, group = "POW") %>% 
  addMarkers(data = sites.eg, ~longitude, ~latitude, label = ~site) %>% 
  addCircleMarkers(data = otts, ~longitude, ~latitude, color = "red", stroke = FALSE, radius = 5, fillOpacity = ~(n_otters/max(n_otters)))
```

## Calculating survey density
The general steps are as follows
1. Calculate survey area centered at each survey site and bounded by 2 nm "as the otter swims". It is essential that site points intersect the water polygon!
2. Calculate area of above survey area
3. Calculate density by counting number of otters in each area (and each survey instance if necessary) and dividing by the survey area

The following for loop generates a 2nm (== 3704 meter) as the otter swims survey area for each sites. It then selects the otters that were where sited in that survey area and generates a data table of that data. This is done for each site iterativley and the resulting data frames are pasted together. 
```{r loop to extract surveyed otters to sites}
d <- data.frame() # set up blank data frame to append to later
for(i in unique(1:21)){
  s <- sites.eg[i,] # subset sites 
  b <- gBuffer(s, byid = TRUE, width = 3704, quadsegs = 10) # create 3704 meter radius buffer around site
  b <- spTransform(b, CRS("+init=epsg:4326")) # change projection to for next step
  bw <- gIntersection(h2o.latlong, b, byid = TRUE) # clip the buffer area by water so we only have water area left
  bw <- spTransform(bw, CRS("+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0")) # change projection back to UTM
  e <- extent(bw) # save the extent of the polygon for later use
  r <- raster(xmn = e@xmin, xmx = e@xmax, ymn = e@ymin, ymx = e@ymax, ncol = (e@xmax - e@xmin) / 50, nrow = (e@ymax - e@ymin) / 50, crs = "+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0") # create a raster with 50 X 50 meter grid cells. This raster is "empty"
  wr <- rasterize(bw, r, crs = "+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0") # append water polygon data to raster. This raster is "full"
  wr[wr] <- 50 # convert all raster cell values to a value of 50 (because 50 meters)
  wt <- transition(wr, transitionFunction = function(x){50}, directions = 8) # conver raster to transition layer (required for accCost() below)
  wt <- geoCorrection(wt, type = "r", scl = FALSE) # not really sure what this actually does but you have to do it
  sa <- accCost(wt, s) # calculate the cumulative cost distance
  values(sa) <- (values(sa) * 50) # multiply cost values by 50 to reflect cost in terms of actual distance
  sa[values(sa) > 3700] <- NA # Convert cost rasters > 3700 to NA, now the raster will reflect the true survey area
  p <- rasterToPolygons(sa, dissolve = TRUE) # covert raster to polygon
  p <- spTransform(p, CRS("+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs")) # define projection
  a <- (2500 * length(p) / 1000000) # caculate area of the polygon in sq km. 2500 becasue 50*50=2500
  o <- over(p, otts) # identifies surveyed otters that intersect/overlap with the polygon
  o <- as.data.frame(unique(o)) # convert that subset of otters to a data frame
  o$area <- a # append the area of the polygon to that data frame
  d <- rbind(d, o) # bind this data frame to the master one. -----> now go back to the top and start again!
}
```

Now we need to clean up the data frame generated in the for loop so that it is usable. *This will differ for everyone*.
```{r clean up data from above}
# Rename L05 to 2017_L_05
levels(d$site)[levels(d$site) == "L05"] <- "2017_L_05"

# Count total otters are each site survey date
ott.dat <- d %>% 
  group_by(site, survey_dat) %>% 
  summarise(n = sum(n_otters))

# Clean up NA row and funky site names
ott.dat <- ott.dat[c(1:8, 10:20, 22:30),]

# Fill in data. These are instances where multiple sites were surveyed at the same time.
fill <- data.frame(c("2017_H_04", "2017_H_06", "2017_M_02", "2017_M_03"), c("2017/07/21", "2017/07/21", "2017/08/05", "2017/08/05"), c(81,81,14,14))
colnames(fill) <- c("site", "survey_dat", "n")

# Compine fill in data with original and re summarise
ott.dat <- rbind.data.frame(ott.dat, fill)
ott.dat2 <- ott.dat %>% 
  group_by(site, survey_dat) %>% 
  summarise(n_otters = sum(n))

# Define survey 1 and 2
ott.dat2$survey <- as.factor(c(1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,2,1,2,1))
ott.dat.wide <- spread(ott.dat2[,c(1,3,4)], key = survey, value = n_otters)

# Merge with site data
site.dat <- sites.eg@data[,c(1,2,6:9)]
site.dat$area <- unique(d$area)
site.dat <- merge(site.dat, ott.dat.wide, by = "site", all.x = TRUE)
colnames(site.dat)[8] <- "n_surv1"
colnames(site.dat)[9] <- "n_surv2"

# NAs to 0
site.dat[is.na(site.dat)] <- 0

# Calculate density
site.dat$dens_surv1 <- site.dat$n_surv1 / site.dat$area
site.dat$dens_surv2 <- site.dat$n_surv2 / site.dat$area
```

Lets view the final table.
```{r}
DT::datatable(site.dat, caption = "Sea otter survey data")
```

# 2. Duration of sea otter occupation
Now we need to assign a duration of sea otter occupation from USFWS surveys. What we are going to do is assign each site a sea otter duration based on if that site intersected the 2003 or 2010 sea otter distribution.

## Data
You will need data on. Note that what polygons you need will depend on you area of interest. This is for POW.
1. Sites from which sea otter surveys were centered from (points) - you should already have this from above
2. 2003 sea otter distrubution polygon
3. 2010 sea otter distribution polygon

```{r}
## USFWS polygons ##
# 2003 Sea Otters
sd2003 <- readOGR(dsn = "../ALL_DATA/spatial_data", layer="Sea_Otter_disp_2003") 

# 2010 Sea Otters
sd2010 <- readOGR(dsn = "../ALL_DATA/spatial_data", layer="Sea_Otter_disp_2010") 
```

Let take a look
```{r}
leaflet() %>% 
  addTiles() %>% 
  addPolygons(data = sd2010, stroke = NA, fillColor = "blue", fillOpacity = 0.8, group = "2003") %>% 
  addPolygons(data = sd2003, stroke = NA, fillColor = "orange", fillOpacity = 0.8, group = "2010") %>% 
  addMarkers(data = sites.eg, ~longitude, ~latitude, label = ~site)
```

Assign year to site.
```{r}
# 2003
sd2003.utm <- spTransform(sd2003, CRS("+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"))
disp.03 <- sites.eg[sd2003.utm,]
disp.03 <- disp.03@data

# 2010
sd2010.utm <- spTransform(sd2010, CRS("+proj=utm +zone=8 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"))
disp.10 <- sites.eg[sd2010.utm,]
disp.10 <- disp.10@data

# Compare
comp <- intersect(disp.03$site, disp.10$site)

# Append to master data
site.dat$sea_otter_duration <- ifelse(match(site.dat$site, comp), 14)
site.dat$sea_otter_duration[is.na(site.dat$sea_otter_duration)] <- 7
```

Lets view the final table
```{r}
DT::datatable(site.dat)
```

# 3. Sea otter density from Tinker et. al
Like with the sea otter duration data we need to assign the modeled sea otter population density to each site.

You will need data on. Note that what polygons you need will depend on you area of interest. This is for POW.
1. Sites from which sea otter surveys were centered from (points) - you should already have this from above
2. The population area polygons from Tim
3. Table of population densities for each Subpop

```{r}
## Tim's survey density blocks ##
poparea.utm <- readOGR(dsn = "../ALL_DATA/spatial_data", layer = "Hab_All_UTM")
poparea.latlong <- spTransform(poparea.utm, CRS("+init=epsg:4326"))

subpop.dens <- read.csv("../ALL_DATA/Subpop_density_Tinker.csv", header = TRUE, stringsAsFactors = FALSE)
```

Let take a look
```{r}
leaflet() %>% 
  addTiles() %>% 
  addPolygons(data = poparea.latlong, stroke = NA, fillOpacity = 0.8, group = "2003") %>% 
  addMarkers(data = sites.eg, ~longitude, ~latitude, label = ~site)
```

Looks like we only need three of these subpopulations so lets reduce the file to individual files.
```{r}
int <- over(sites.eg, poparea.utm)
unique(int$Subpop)

poparea.S02.utm <- poparea.utm[poparea.utm$Subpop == "S02",]
poparea.S03.utm <- poparea.utm[poparea.utm$Subpop == "S03",]
poparea.S06.utm <- poparea.utm[poparea.utm$Subpop == "S06",]
```

Assign population to site
```{r}
# S02
S02 <- sites.eg[poparea.S02.utm,]
S02 <- S02@data
S02$dens <- subpop.dens$current_dens[subpop.dens$Subpop == "S02"]

#S03
S03 <- sites.eg[poparea.S03.utm,]
S03 <- S03@data
S03$dens <- subpop.dens$current_dens[subpop.dens$Subpop == "S03"]

#S06
S06 <- sites.eg[poparea.S06.utm,]
S06 <- S06@data
S06$dens <- subpop.dens$current_dens[subpop.dens$Subpop == "S06"]

# Merge all these together
dens <- rbind.data.frame(S02, S03, S06)

# Append to master data
site.dat$pop_mod_dens <- ifelse(match(site.dat$site, dens$site), dens$dens)

```

Lets view the final table
```{r}
DT::datatable(site.dat)
```

# 4. Number of sea otter pits
We want to take into account the number of sea otter pits at a site. 

## Data
For this you will need
1. The sea otter pit data
```{r}
pits <- read.csv("../ALL_DATA/TIFF_seagrass_carbon_disturbance/2017_data_efforts/seagrass_seaotter_pit_sediment_2017_RAW.csv", stringsAsFactors = FALSE, header = TRUE)
```

We now want to sum to the total number of pits at each site and append that to our master data
```{r}
# Summarise
pits.site <- pits %>%  
    group_by(site) %>% 
    summarise(n_pits = sum(pit_bin))

pits.site <- pits.site[2:22,] # removes weird row with nothing in it

# Append to master
site.dat$n_pits <- ifelse(match(site.dat$site, pits.site$site), pits.site$n_pits)
```

# 5. Proportion of sea otter crakced clam shells
Finally we want to account for the proportion are clam shells that appear to have been cracked (consumed) by sea otters.

## Data
You will need
1. Sea otter clam data
```{r}
shell <- read.csv("../ALL_DATA/seagrass_clam_shells_2017_RAW.csv", stringsAsFactors = FALSE, header = TRUE)
```

The data will need to be summed by site and then converted to a proportion and appended to the rest of the data
```{r}
shell.site <- shell %>%
    group_by(Site, Death) %>% 
    summarise(n_shells = n())

# Proportion of shells that where sea otter cracked by site
prop.shell <- shell.site %>% 
  group_by(Site) %>% 
  summarise(n_SO_shells = n_shells[Death == "Sea Otter"], n_Total_shells = sum(n_shells))

prop.shell$prop_SO_shells <- (prop.shell$n_SO_shells / prop.shell$n_Total_shells)

# Append to master
site.dat$prop_otter_shells <- ifelse(match(site.dat$site, prop.shell$Site), prop.shell$prop_SO_shells)
```

# Calculating the actual index
Congratulaiton! You can calculated and complied all the data you need to actually calculate the index

## Data
You will need the data frame that we have been building above "site.dat"
Lets view the final table
```{r}
DT::datatable(site.dat)
```

## Sea otter impact index
We will be using a principle components analysis to create the sea otter impact index. First its good practice to examine the data a bit. Correlation plots indicate that most measures are reasonably correlated with eachother.
```{r data exploration}
# Correlations
corrgram(site.dat[,10:15])
pairs(site.dat[,10:15])
```

### Assessing normality of measures

Some measures are fairly skewed because of zeros and extreme values. Transforming would help control for these extreme values. Below are untransformed histograms

#### read in if you don't want to re-run all of the above
```{r read already caculated}
site.dat <- read.csv( "../ALL_DATA/sea_otter_impact_index_new.csv", header = TRUE, stringsAsFactors = FALSE)
```


```{r}
hist(site.dat$dens_surv1)
hist(site.dat$dens_surv2)
hist(site.dat$n_pits)
hist(site.dat$prop_otter_shells)
```

Transformations
```{r}
hist(log(site.dat$dens_surv1))
hist(log(site.dat$dens_surv2))
hist(log(site.dat$n_pits + 1))
hist(asin(sqrt(site.dat$prop_otter_shells)))
```

Create transformed dataset
```{r}
site.dat.tr <- cbind(site.dat[, 1:9], log(site.dat[, 10:11] + 1), site.dat[, 12:13], log(site.dat[, 14] + 1), asin(sqrt(site.dat[, 15])))
```

### Standardizations. Measures will be standardized across sites to column maximum
```{r standardizations}
# Separate values only
dat.redu <- site.dat[, 10:15]
dat.redu.tr <- site.dat.tr[, 10:15]

# Standardize to column (sea otter measure) maximum
dat.std <- scale(dat.redu, center = FALSE, scale = apply(dat.redu, 2, max))
dat.std.tr <- scale(dat.redu.tr, center = FALSE, scale = apply(dat.redu.tr, 2, max))
```

Now we can calculate the PCA - no transformation
```{r PCA stand only}
# PCA on standarized data
pca <- princomp(dat.std)
pca.summary <- summary(pca)
pca.summary
pca
loadings(pca)
biplot(pca, cex = 1)
screeplot(pca, ylim = c(0, 0.8))
pca$scores 

final.dat <- cbind(site.dat, pca$scores[,1])
colnames(final.dat)[16] <- "sea_otter_index"

ggplot(final.dat, aes(site, sea_otter_index)) +
  geom_point(size = 4) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Site", y = "Sea otter index (PC1)")

ggplot(final.dat, aes(reorder(site, sea_otter_index), sea_otter_index, col = sea_otter_index)) +
  geom_point(size = 4) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(x = "Site", y = "Sea otter impact Index", col = "Sea otter impact Index") +
  theme(text = element_text(size = 12), axis.ticks = element_line(size = 2)) +
  theme(axis.text.x = element_text(angle = 90))
```

Now we can calculate the PCA - transformation
```{r trans and std data}
pca.tr <- princomp(dat.std.tr)
pca.summary.tr <- summary(pca.tr)
pca.summary.tr
pca.tr
loadings(pca.tr)
biplot(pca.tr, cex = 1)
screeplot(pca.tr, ylim = c(0, 0.8))
pca.tr$scores 

final.dat.tr <- cbind(site.dat.tr, pca.tr$scores[,1])
colnames(final.dat.tr)[16] <- "sea_otter_index"

ggplot(final.dat.tr, aes(site, sea_otter_index)) +
  geom_point(size = 4) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Site", y = "Sea otter index transformed (PC1)")

ggplot(final.dat.tr, aes(reorder(site, sea_otter_index), sea_otter_index, col = sea_otter_index)) +
  geom_point(size = 4) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(x = "Site", y = "Sea otter index transformed", col = "Sea otter impact Index") +
  theme(text = element_text(size = 12), axis.ticks = element_line(size = 2)) +
  theme(axis.text.x = element_text(angle = 90))

# no color
ggplot(final.dat.tr, aes(reorder(place_name, sea_otter_index), sea_otter_index)) +
  geom_point(size = 4) +
  labs(x = "Site", y = "Sea otter index transformed", col = "Sea otter impact Index") +
  scale_y_continuous(limits = c(-0.8, 1.2), breaks = seq(-0.8, 1.2, by = 0.4)) +
  theme(text = element_text(size = 12), axis.ticks = element_line(size = 2)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Compare non tranformed and transformed versions
```{r}
plot.ntrans <- ggplot(final.dat, aes(reorder(place_name, sea_otter_index), sea_otter_index, col = sea_otter_index)) +
  geom_point(size = 4) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(x = "Site", y = "Sea otter impact Index", col = "Sea otter impact Index") +
  theme(text = element_text(size = 12), axis.ticks = element_line(size = 2)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

plot.trans <- ggplot(final.dat.tr, aes(reorder(place_name, sea_otter_index), sea_otter_index, col = sea_otter_index)) +
  geom_point(size = 4) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(x = "Site", y = "Sea otter index transformed", col = "Sea otter impact Index") +
  theme(text = element_text(size = 12), axis.ticks = element_line(size = 2)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

plot_grid(plot.ntrans, plot.trans)
```


Final index data table
```{r}
DT::datatable(final.dat, caption = "Sea otter impact index")
DT::datatable(final.dat.tr, caption = "Sea otter impact index")
```

## Data export
```{r export}
# Combine transformed and untransformed versions
final.dat.all <- final.dat
final.dat.all$sea_otter_index_tr <- final.dat.tr$sea_otter_index
DT::datatable(final.dat.all, caption = "Sea otter impact index")

# Data Export
write.csv(final.dat.all, "../ALL_DATA/sea_otter_impact_index_new.csv", row.names = FALSE)
```

## Collated Results
Reduce full data and organise for publication
```{r}
## Reduce full data and organise / clean up
final.dat.redu <- final.dat[, c(2, 7, 10:16)]
final.dat.redu <- cbind.data.frame(final.dat.redu$place_name, round(final.dat.redu[, 2:9], 2))
final.dat.redu <- final.dat.redu[order(final.dat.redu$sea_otter_index, decreasing = TRUE),]

## Export ##
write.csv(final.dat.redu, "../Seagrass_2017/Eelgrass_structure_MS_results/Sea_otter_index_results.csv", row.names = FALSE)
```

