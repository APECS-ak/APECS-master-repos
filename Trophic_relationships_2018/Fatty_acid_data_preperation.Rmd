---
title: "Fatty_acid_data_preperation"
author: "Wendel Raymond"
date: "September 24, 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Fatty acid data preperation
This script will tranform the raw area and concentration data from the FA chromatograph to ready for analysis. This include combining raw files into a master tall dataframe, and preforming initioal proportion calculations.

```{r libraries, echo=FALSE}
library(tidyverse)
```

## Data
Import all FA area/concentration data and dry weight data

### Area and concentration data
Naming will follow the convension of
batch#_type
example: b1_area is batch 1 area data

```{r data area conc, echo=FALSE}
## Batch 1 ##
b1_area <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_1_Area_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

b1_conc <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_1_Conc_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

## Batch 2 ##
b2_area <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_2_Area_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

b2_conc <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_2_Conc_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

## Batch 3 ##
b3_area <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_3_Area_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

b3_conc <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_3_Conc_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

## Batch 4 ##
b4_area <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_4_Area_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

b4_conc <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_4_Conc_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

## Batch 5 ##
b5_area <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_5_Area_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

b5_conc <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_5_Conc_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

## Batch 6 ##
b6_area <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_6_Area_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

b6_conc <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_6_Conc_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

## Batch 7 ##
b7_area <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_7_Area_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

b7_conc <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_7_Conc_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

## Batch 8 ##
b8_area <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_8_Area_RAW.csv", stringsAsFactors = FALSE, header = TRUE)

b8_conc <- read.csv("../ALL_DATA/Fatty_acid_RAW_data/Batch_8_Conc_RAW.csv", stringsAsFactors = FALSE, header = TRUE)
```

### Dry sample mass data
```{r data mass, echo = FALSE}
samp_mass <- read.csv("../ALL_DATA/Biomarker_extraction_mass_2018_RAW.csv", stringsAsFactors = FALSE, header = TRUE)
samp_mass$Weigh_date <- as.Date(samp_mass$Weigh_date, "%m/%d/%Y")
samp_mass$Extraction_date <- as.Date(samp_mass$Extraction_date, "%m/%d/%Y")

samp_mass_redu <- samp_mass %>% 
  filter(Notes != "error in extraction") %>% 
  filter(Biomarker_ID != "B_004" & sample_on_foil_mg != 22.67) %>% 
  filter(Biomarker_ID != "B_160")
```


## Compile area and concentration data to tall data
Combine all batch data and convert to tall format. Preserve batch number identity for claculations and figuring out any data issues. Clean up sample names.
```{r combine, echo = FALSE}
## Batch 1 ##
b1_ac <- gather(b1_area, key = "FA", value = "Area", 2:56)
b1_ac$Conc <- gather(b1_conc, key = "FA", value = "Conc", 2:56)[,3]
b1_ac$Batch <- as.character(1)

## Batch 2 ##
b2_ac <- gather(b2_area, key = "FA", value = "Area", 2:61)
b2_ac$Conc <- gather(b2_conc, key = "FA", value = "Conc", 2:61)[,3]
b2_ac$Batch <- as.character(2)

## Batch 3 ##
b3_ac <- gather(b3_area, key = "FA", value = "Area", 2:55)
b3_ac$Conc <- gather(b3_conc, key = "FA", value = "Conc", 2:55)[,3]
b3_ac$Batch <- as.character(3)

## Batch 4 ##
b4_ac <- gather(b4_area, key = "FA", value = "Area", 2:50)
b4_ac$Conc <- gather(b4_conc, key = "FA", value = "Conc", 2:50)[,3]
b4_ac$Batch <- as.character(4)

## Batch 5 ##
b5_ac <- gather(b5_area, key = "FA", value = "Area", 2:60)
b5_ac$Conc <- gather(b5_conc, key = "FA", value = "Conc", 2:60)[,3]
b5_ac$Batch <- as.character(5)

## Batch 6 ##
b6_ac <- gather(b6_area, key = "FA", value = "Area", 2:69)
b6_ac$Conc <- gather(b6_conc, key = "FA", value = "Conc", 2:69)[,3]
b6_ac$Batch <- as.character(6)

## Batch 7 ##
b7_ac <- gather(b7_area, key = "FA", value = "Area", 2:56)
b7_ac$Conc <- gather(b7_conc, key = "FA", value = "Conc", 2:56)[,3]
b7_ac$Batch <- as.character(7)

## Batch 8 ##
b8_ac <- gather(b8_area, key = "FA", value = "Area", 2:57)
b8_ac$Conc <- gather(b8_conc, key = "FA", value = "Conc", 2:57)[,3]
b8_ac$Batch <- as.character(8)

## Combine all batches together ##
FA_ac <- rbind(b1_ac, b2_ac, b3_ac, b4_ac, b5_ac, b6_ac, b7_ac, b8_ac)

## Add ID column ##
FA_ac$ID <- substr(FA_ac$Sample, 1, 5)

## Arrange ##
FA_ac <- cbind(FA_ac[, c(6,1,5,2,3,4)])

## To numeric ##
FA_ac$Area <- as.numeric(FA_ac$Area)
FA_ac$Conc <- as.numeric(FA_ac$Conc)
```

## Calculate proportion by area
For a sample, calculate the proportion of each unique FA as the area of that FA divided my the total area of all FAs of that sample. NOTE that C19 is removed for this calculation. NOTE any area and concentration data that is imported at a negative number will be converted to a zero.

```{r calc, prop, echo = FALSE}
## Convert neg to zero ##
FA_ac$Area <- ifelse(FA_ac$Area < 0, 0, FA_ac$Area) 
FA_ac$Conc <- ifelse(FA_ac$Conc < 0, 0, FA_ac$Conc) 

## Calcualte proportion of total sample area ##
FA_ac <- FA_ac %>% 
  filter(str_detect(ID, "^B_")) %>%
  filter(FA != "C19.0") %>% 
  group_by(ID) %>%
  mutate(Total_area = sum(Area))

FA_ac$Prop_area <- FA_ac$Area / FA_ac$Total_area
```

## C19 standard data

### Extract C19 data 
Multiple C19 satandards were made for all the extractions. The concentration of theses standard will be extracted from the sample mass data and to make a new dataframe where standards can be assigned to extractions days.

```{r c19, echo = FALSE}
## filter C19 data ##
C19 <- samp_mass_redu %>% 
  filter(Species_common == "C19")

## Calcualte concentration ##
C19$C19_conc_mgL <- C19$sample_extracted_mass_mg / c(6.5, 10, 10)
```


### Assign C19 concentrations standards to extraction days
DIffernet C19 solutions were used on different extraction days. 

C19.2.25 was used on extraction days 2.25.2019 to 3.26.2019
C19.2.27 was used on extraction days 2.27.2019 to 3.9.2019
C19.3.10 was used on extraction days 3.10.2019 to 3.19.2019

```{r assign concentration, echo = FALSE}
samp_mass_redu$C19_conc <- NA
samp_mass_redu$C19_conc[which(samp_mass_redu$Extraction_date == "2019-02-25")] <- C19$C19_conc_mgL[C19$Biomarker_ID == "C19_2.25"]
samp_mass_redu$C19_conc[which(samp_mass_redu$Extraction_date > "2019-02-25" & samp_mass_redu$Extraction_date <= "2019-03-09")] <- C19$C19_conc_mgL[C19$Biomarker_ID == "C19_2.27"]
samp_mass_redu$C19_conc[which(samp_mass_redu$Extraction_date > "2019-03-09")] <- C19$C19_conc_mgL[C19$Biomarker_ID == "C19_3.10"]
```

### Calculate recovery
Using C19 data we will calcualte the proporiton recovered as a way to assess our extraction.
```{r recov, echo = FALSE}
FA_ac <- merge(FA_ac, samp_mass_redu[, c(1, 2,  7, 9)], by.x = "ID", by.y = "Biomarker_ID")

FA_C19_recov <- FA_ac %>% 
  filter(FA == "C19.0")

FA_C19_recov$Recovery <- (FA_C19_recov$Conc  / (((FA_C19_recov$C19_conc * 1000 * 70) / 1500) * 0.666667))
```

## Remove small FAs
We will filter out all FAs that constitute less than 0.5% or less than 1.0% of a samples total FA area. We will then examine how many FAs are lost in these two methods.
```{r reduce, echo = FALSE}
## Filter out less than 0.5% ##
FA_ac_0.5 <- FA_ac %>%
  filter(Prop_area >= 0.005) %>% 
  group_by(ID) %>%
  mutate(Total_area_0.5 = sum(Area))

FA_ac_0.5$Prop_area_0.5 <- FA_ac_0.5$Area / FA_ac_0.5$Total_area_0.5

## Filter out less than 1.0% ##
FA_ac_1.0 <- FA_ac %>%
  filter(Prop_area >= 0.01) %>% 
  group_by(ID) %>%
  mutate(Total_area_1.0 = sum(Area))

FA_ac_1.0$Prop_area_1.0 <- FA_ac_1.0$Area / FA_ac_1.0$Total_area_1.0
```


## Examine area proportion
Compute summary proporional data to identify outliers.

```{r prop exam, echo = FALSE}
## Sum n samples by tissue ##
FA_samps <- data.frame(unique(FA_ac[, c(1,9)]))
FA_samps.n <- FA_samps %>% 
  group_by(Species_common) %>% 
  summarise(n_all_sp = n())

sp_prop_summary_0.5 <- FA_ac_0.5 %>%
  group_by(Species_common, FA) %>% 
  summarise(n = n(),
            mean_prop_corr = mean(Prop_area_0.5),
            sd_prop_corr = sd(Prop_area_0.5),
            min_prop_corr = min(Prop_area_0.5),
            max_prop_corr = max(Prop_area_0.5))

sp_prop_summary_1.0 <- FA_ac_1.0 %>%
  group_by(Species_common, FA) %>% 
  summarise(n = n(),
            mean_prop_corr = mean(Prop_area_1.0),
            sd_prop_corr = sd(Prop_area_1.0),
            min_prop_corr = min(Prop_area_1.0),
            max_prop_corr = max(Prop_area_1.0))
```

## Prep for multivariate analysis
Convert tall data to wide for multivarite analysis. General structure will be sample data columns followed by FA columns with zeros filling instances when a sample did not have a FA that other samples did.

```{r tall to wide, echo = FALSE}
## 0.5% filter data ##
FA_prop_0.5 <- spread(FA_ac_0.5[, c(1, 4, 9, 13)], key = FA, value = Prop_area_0.5)

FA_prop_0.5[is.na(FA_prop_0.5)] <- 0

## 1.0 % filter data ##
FA_prop_1.0 <- spread(FA_ac_1.0[, c(1, 4, 9, 13)], key = FA, value = Prop_area_1.0)

FA_prop_1.0[is.na(FA_prop_1.0)] <- 0

```

### Export wide data
```{r export wide, echo = FALSE}
## 0.5% filter ##
write.csv(FA_prop_0.5, "../ALL_DATA/FA_proportions_0.5filter_2018_derived.csv", row.names = FALSE)

## 1.0% filter ##
write.csv(FA_prop_1.0, "../ALL_DATA/FA_proportions_1.0filter_2018_derived.csv", row.names = FALSE)
```

